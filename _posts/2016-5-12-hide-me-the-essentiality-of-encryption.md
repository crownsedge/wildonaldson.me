---
published: true
title: "Hide Me: The essentiality of encryption in our globally digital world"
layout: post
---

> _This paper was written for the class_ Global Media _at SUNY New Paltz in May of 2016._

If there is one technology that can be said to be essential to the birth and subsequent flourishing of our modern, digital world, it is encryption. In a basic sense, encryption technologies protect information by “encrypting” it, using a key, into something that no longer resembles the original signal, but is still able to be decrypted using the key. This simple principle is responsible for so much of the new digital era we all reside in. Things like online shopping, web-based banking, and secure person-to-person communications would be impossible without it. Before it protected our personal information, however, it protected government and military secrets. For many decades, encryption technologies have been used on “military, diplomatic, and government missions” (Schwartzbeck 21). In fact, in the past, encryption technologies were considered government munitions (Schwartzbeck 24), and to this day, export of some forms of encryption software is internationally controlled (The Wassenaar Arrangement 85-90).  

There are two primary forms of encryption that are used in modern systems. The first, symmetric key encryption, single-key encryption, or private-key encryption, has its roots in the DES, or Data Encryption Standard, developed at IBM, and, in 1977, adopted federally as Federal Information Processing Standard 46 (Pilkington 168-169; Diffie 2). This type of encryption uses a single key for both encrypting and decrypting the information. While important historically, and central to the basic concepts that modern cryptography uses, it is not the primary type of encryption utilized in modern communications technologies. The idea of public-key encryption, or asymmetric key encryption, was proposed in 1976 by Whitfield Diffie, Martin E. Hellman and Ralph C. Merkle (Pilkington 169; Rivest 116). This new kind of encryption is notable for two reasons — first, it enables two parties to communicate over an insecure channel without creating a private key in advance, and second, it provides a “digital signature mechanism” not unlike a written signature (Diffie 3). It is this kind of encryption that enables modern communications, internet commerce, and electronic banking (Diffie 2). Unlike private-key encryption, public-key encryption sees each party using two different keys — a private key and a public key. To send a message, the sending party uses the receiving party’s public key to encrypt it, and the receiving party uses their private key to decrypt it (Pilkington 169). This concept revolutionized the cryptography field in the late 1970s, and the United States government did not like it one bit.

The United States has been involved in the creation, use, and defeat of cryptographic maths at minimum since World War II, where its defeat of the German and Japanese encryption technologies proved invaluable to the Allied effort (Schwartzbeck 21). A Top Secret-classified report from the Central Intelligence Agency’s Studies in Intelligence journal, authored by Michael Schwartzbeck in 1997 and released to the public under a Freedom of Information Act request, gives a number of insights into the United States government’s hegemonic treatment of the cryptographic world. “For decades,” Schwartzbeck writes, “the US Government has monopolized encryption and decryption efforts, capabilities and research. In recent years, however, […] several academic, commercial, and free speech advocates have seriously jeopardized the US Government’s legal right to control encryption” (21). This simple passage underscores the United States’ position on cryptography — as the leading world power, they should have supreme control of it. Through their work with the Wassenaar Arrangement, which this paper will touch on later, this hegemonic desire perseveres to this day, if somewhat diminished in power. Later in the piece, Schwartzbeck writes about the Lucifer cipher, a direct precursor to the original IBM DES cypher (Sorkin):

> At first, the Lucifer cipher was not very sophisticated, but […] IBM retooled the cipher a number of times; in 1974, it was ready for the market. This cipher had a key that was 128 bits long, significantly longer than the keys of any other publicly developed encryption programs available to the public at the time.

This incredibly long cipher key led many to believe that the Lucifer code would be truly unbreakable, even by NSA’s standards. For the first time in its history, NSA’s decryption capabilities were seriously threatened by public research, and the agency quickly moved to rectify the situation. (22)

From here, the remainder of the paragraph is censored — covered in a white box, the likes of which pepper many government documents released under the Freedom of Information Act. It remains unknown exactly how they “moved to rectify” the problem that Lucifer caused, but their eventual partnership with IBM to develop DES, which is a direct descendant of this Lucifer cypher, is likely at least one consequence of that process (Sorkin). In its final version, DES more than chops Lucifer’s original key length in half, resulting in a 56-bit key length (Pilkington 170).

With the United States’ hegemonic desire to maintain a strong grip on encryption — and the cryptographic community as a whole — well established, it makes sense to discuss just how they planned to exercise this control, aside from inserting themselves into the offices of those companies developing the technologies. Before any of our modern use of cryptographic technologies, encryption was only seen as something that would benefit the military and government. Its primary use for intelligence gathering and securing communications led the National Security Agency and the Defense Department to be key players in both its development and the control over its use (Pilkington 162). Over the course of the 20th century, it transformed from a process done by hand and prone to error into a ‘quick, reliable, and inexpensive’ process that computers could perform at unimaginable rates (Diffie 2). In the process, as non-government entities could justify use of the technology, and independent companies began to create their own encryption mechanisms, the United States began to lose its grip on control of encryption. One of the United States’ most direct and immediate ideological concerns caused by this loss of control is that, if this encryption software is publicly available, it can then fall into the hands of terrorists, criminals, spies, and unfriendly nation-states, who would then have the ability to interact over public networks without being able to be monitored (Rivest 116, Schwartzbeck 23). The natural result of this concern are export controls.

Whitfield Diffie, one of the original creators of public-key encryption, and Susan Landau posit that today’s export control laws, as liberal as they have become, have their ultimate roots in the Cold War (4). At the end of World War II, an international group called COCOM, standing for Coordinating Committee for Multilateral Export Controls, was formed by 17 countries, including the United States, in order “to control exports from the West to the former Warsaw Pact and other communist countries” (Broadbent; Torrubia 725). The United States’ own export controls are the result of the 1949 Export Control Act, which acted as “an administration and control system for exports of dual-use technologies and conventional arms” (Broadbent). Here, in this immediately post-World War II period, all cryptography was considered a munition, and remained such long past it seeming sensible to outside observers (Diffie 6).

These Cold War-era export regulations lasted through 1994, when the Export Control Act’s successor, the Export Administration Act, along with COCOM itself, was sunsetted. In March of 1994, the COCOM nations met in Wassenaar, Netherlands, and the Wassenaar Arrangement was established by 33 countries on December 19, 1995 (Broadbent). The Wassenaar Arrangement, like COCOM before it, set up a list of munitions and what it calls “dual-use” goods (The Wassenaar Arrangement). These dual-use items are exports that are deemed to have both military and civilian utility (Diffie 4). Encryption, thus, falls under the dual-use identifier, and specifically under Category 5, Part 2, titled “Information Security” (The Wassenaar Arrangement).

In addition to export controls, the Clinton administration attempted to exert control over encryption in a number of other (sometimes embarrassing) manners. In April of 1993, in a move to regain NSA control over encryption, the administration offered the idea of what they called a “Clipper chip.” This chip would have been placed in all US-manufactured computers, and would allow the United States to “hold copies of every key in use by the public”, to the end of enabling themselves to decrypt any message it wanted. The idea was widely reviled, and thankfully did not gain traction. The Clinton administration later attempted to influence the encryption industry to adopt DES for all its encryption, but critics of this idea said that the 56-bit keys that DES was forced to use were no longer strong enough for modern encryption needs (Schwartzbeck 23).

Export controls would thus remain an important tool in the United States’ arsenal. Over time, the country realized that these export controls would serve to not only limit the proliferation of strong cryptography throughout the world, but within their own country as well (Diffie 7-8). Diffie and Landau say that three factors make this possible. First, “[t]he export market in computer hardware and software is huge”, with the average American computer company making “more than half of its sales abroad” (7). Second, these computers need security as a “supporting feature”. As Diffie and Landau write, “no system exists for the primary purpose of being secure” — meaning that the security aspects act best as a component of a larger puzzle, instead of a discrete system later added on to an otherwise finished product (8). Finally, it behooves these computer companies to make a single product line that interoperates in both domestic and foreign markets — thus, the security systems cannot be distinct between computers made for a domestic market and those made for a foreign one (8). These factors combine to create an environment here at home that fosters the use of encryption that is less strong in order for United States computer companies to be economically successful.

Of course, they would be more successful if they were allowed to use strong encryption in the first place. As Diffie and Landau note, United States-based companies have the chance to lose the business of “security-conscious customers” to foreign companies who are more willing or able to provide the security needs they are looking for. Europe and Asia, they noted, both have quickly growing computer industries, both with many incentives to displace the United States’ vice grip on the computing world (8).

Nevertheless, the Clinton administration was still a very strict fan of prohibiting United States companies from exporting products using strong encryption (Schwartzbeck 24). Throughout its tenure, that administration faced several important challenges that, in the end, helped pave the way towards the more liberal export controls we have today. One of these was from RSA Security. The scientists behind RSA had created a public-key encryption program that they sold Apple, Motorola, and other companies the right to use (Pilkington 171, Schwartzbeck 23). The problem came when they wanted to sell it to Microsoft — they wanted to use the software in products they would sell abroad (Schwartzbeck 23). In the end, RSA would get a license to export two products, and neither with keys longer than 40 bits (Diffie 8). Even then, in 1992, according to Diffie, a 40-bit key could be cracked in as little as a month (9). Later, RSA would go on to give the United States even more problems. RSA had a problem in that it was unable to export most of its products, especially ones with very strong keys. However, the laws pertaining to encryption technologies were only United States laws. By creating an independent subsidiary in Japan, RSA found itself able to license their technologies to other Japanese corporations, newly unencumbered by those laws (Schwartzbeck 24).

Another important story is that of a piece of software called Pretty Good Privacy, or PGP. This piece of open-source software was made to encrypt email transmissions, and it was capable of using extremely strong keys for the time — keys that were 1,024 bits in length were not unheard of. Being a shareware program, however, the State Department found itself unable to place controls on the software before it found itself widely distributed. In the end, the cryptographer responsible for the software, Philip Zimmerman, found himself in court, but he was eventually acquitted (Diffie 9; Schwartzbeck 24).

The United States, thus, is no stranger to finding itself in trouble when trying to regulate and control encryption. In time, they found some stability — Clinton’s Executive Order 13206, “Administration of Export Controls on Encryption Products”, was, in November of 1996, a direct response to June 1996’s CRISIS, or “Cryptography’s Role In Securing the Information Society”, report released by the National Research Council. 500 pages long, it recommended for relaxing of export control restrictions, the proliferation of “widespread commercial and private use cryptography”, and re-examination of government’s encryption policies compared to other economic regulations. Clinton conceded to a lot of these — “cryptographic hardware, software, and technologies” were removed from the Munitions List of the Arms Export Control Act, and reclassified them as “dual-use” technologies.

The United States government has not been completely off the hook since. A random number generator called Dual_EC_DRBG, promoted by both the National Security Agency and the National Institute of Science and Technology and used as part of cryptographic technology, was found to have a backdoor, leaving the average cryptographer’s trust in these organizations to dwindle (Schneier). For the average person, though, these new, liberal export restrictions make public research into new and stronger cryptographic systems stronger than ever before. Further liberalization of European and American export controls, in June and July of 2000, respectively, remove the necessity for export licenses for EU members and their “trading and security partners”, and allow them to export encryptions technologies immediately (Diffie 16). The end result is that technology companies around the world are able to practice strict encryption methods in their products. Without these relaxed export controls, the proliferation of international internet shopping sites like Amazon would simply not be possible. Internet banking would be nowhere near as secure from hackers and thieves. The industry has cryptographers who made open-source software to thank, as their gratis work allowed other organizations to build on their efforts to create platforms such as TLS with strong encryption at its core (Diffie 17). It enables the global Internet to truly be a global Internet. Imagine if websites in foreign countries had to use their own security standards instead of globally interoperable ones — nobody would be able to communicate across borders. In the end, it’s almost a little funny — something that we use to hide information away has brought the world ever closer together.
